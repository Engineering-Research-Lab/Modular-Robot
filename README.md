# CBM - Control Bot Mechanism
## Modular Robot Head Prototype Device

![Modular Robot Head](https://github.com/Engineering-Research-Lab/Modular-Robot-Head/blob/main/image/cbm-robot-modular-head-(3).png)
 
### Content

- [Overview](#overview)
- [CBM Control Bot Mechanism](#cbm-control-bot-mechanism)
- [Functionality](#functionality)
- [Operating System Application Software Library Interface](#operating-system-application-software-library-interface)
- [System Requirements](#system-requirements)
 
## Overview

The Modular Robot Head is an innovative, artistically and industrially designed robotic module that features advanced control algorithms, mechanical engineering, and electronic assembly. It is designed with a transparent face capsule and plastic casing, incorporating a bicolor LED square pixel matrix for displaying emotions and reactions through eyes, nose, and mouth animations. 

## CBM Control Bot Mechanism 

The robot's control mechanism delivers a unique and engaging user experience, suitable for educational, therapeutic, and human-robot interaction research settings. Combining software and mechanical R&D, this initiative targets tailored solutions for therapeutic approaches such as Robot-Assisted Therapy/Training (RAT), addressing psychological and neurological conditions. The CBM robot head aims to explore educational and therapeutic applications through human-machine interaction.

 
## Functionality 

The CBM project presents a modular robot head capsule prototype with facial interactivity functions. It comprises a control application and a humanoid robot device. The control mechanism includes a Speech Viseme Motility Animation display for speech motion. It incorporates a library of functions and software applications.

 
### Speech Animation with Visemes 

- The robot head can animate speech using visemes, providing visual representations of phonemes (speech sounds). This enhances the naturalness of the interaction by synchronizing mouth movements with spoken words.
- The mechanism performs phonetically synchronized speech with a group of mouth lip movements using 21 visemes, according to the Viseme/Phoneme event set reference: [System.Speech.Synthesis Namespace SpeechSynthesizer.VisemeReached Event] 
### Face Detection and Tracking 

- **Face Detection and Tracking**: Integrated video camera inside the capsule for face tracking and coordinated head movement with CV (Computer Vision) usage allows the robot to detect and track faces in real-time.
- **Eyes Gaze Following**: The bicolor LED square pixel matrix mimics the eyes of the robot, dynamically adjusting to follow the observer's gaze, creating an interactive and engaging experience. Transparent Face Capsule houses a bicolor LED square pixel matrix for dynamic emotion and reaction representation with animation sequences for expressive outputs.
- **Neck Orientation**: The neck movement mechanism is synchronized with the face tracking system, enabling the robot's head to orient towards the observer, enhancing the natural interaction between the robot and its user. Neck Movement supports movement along both the Y and X axes, allowing for precise head motions.

<img src="https://github.com/ladooniani/Terbinari-CBM-Robot/blob/main/images/terbinari-cbm1-2.jpg" width="700">
 
The CBM software and device facilitate interactive conversation via AI chatbot and artificial conversational entities connection, offering flexibility for adoption with existing chatbots and AI systems like ChatGPT, primarily serving as an avatar.
 
## Operating System Application Software Library Interface
 
The Humanoid Robot software and device is a tool for interactive training and conversation. It is composed of a chat-bot interface and a humanoid robot control mechanism, which includes a cervical motility device for speech motion and facial detection/recognition. Its robot control mechanism provides a unique and engaging experience for users, making it well-suited for use in educational and therapeutic settings, as well as for human-robot interaction research.

- The robot control mechanism includes eye and head tracking, allowing for eye contact with the user, and lip animation synchronization with speech. 

## System Requirements

The CBM software is designed to be compatible with Microsoft Windows operating systems and requires speech synthesis/recognition references.
The robot control device is powered by a 6V power supply and connects to the computer via USB serial port.

#

ðŸ“Œ [Download PDF](https://github.com/Engineering-Research-Lab/Workflow-Documentation/blob/main/Docs/PDF/Engineering-Research-Lab_CBM-Project.pdf)

<sub>Copyright Â© 2016-2024 <a href="https://github.com/Engineering-Research-Lab">Lado Oniani Engineering Research</a>. All rights reserved.</sub>
